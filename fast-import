#!/usr/bin/env bash

force_import=false

show_help() {
  echo ""
  echo "Usage: $0 -F DUMP_FILE [-d DATABASE_NAME] [-a ASYNC_TABLE_NAMES] [-r REPLACE_FROM] [-t REPLACE_TO]"
  echo "Example: $0 -F backup.sql.gz -d booking -a \"table_name|table2_name\" -f incorrect -t correct"
  exit 1
}

parse_options() {
  while getopts "F:d:a:r:t:f" option; do
  argument=$OPTARG
  ARGS["${option}"]="${argument}"
    case $option in
        h)
            show_help
            exit 0
            ;;
        F)  dump_path=$argument
            ;;
        d)  db_name=$argument
            ;;
        a)  asynchronously_imported_tables_regex=$argument
            ;;
        r)  replace_table_prefix_from=$argument
            ;;
        t)  replace_table_prefix_to=$argument
            ;;
        f) force_import=true
            ;;
        \? ) echo "Invalid option: $argument" 1>&2
            show_help >&2
            ;;
    esac
  done

  if [[ "$force_import" = false ]]; then
    exec 3<>/dev/tty
    read -u 3 -p "This script will destroy the data in the keitaro database, are you sure you want to continue (yes|no)" yn
    case $yn in
        [Yy]*) ;;
        [Nn]*) exit
               ;;
        * )    echo "Please answer yes or no."
               exit
               ;;
    esac
  fi
}

ensure_nobody_is_using_database() {
  local parallel_processes_list=$(mysql --execute='SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST WHERE COMMAND = "Query" AND DB = "keitaro"';)
  if [[ $parallel_processes_list ]]; then
    echo "Database Keitaro used by another process"
    exit 1
  fi
}

ensure_options_are_valid() {
  if [[ -z "${dump_path}" ]]; then
    echo "-d parameter is required"
    show_help
  fi

  if [[ ! -f "$dump_path" ]]; then
      echo "keitaro dump does not exists"
      exit 1
  fi

  if [[ -z "${db_name}" ]]; then
      echo "database name does not set"
      exit 1
  fi

  if [[ -z "${asynchronously_imported_tables_regex}" ]]; then
      echo "tables name does not set"
      exit 1
  fi
}

make_dump_dir() {
  mktemp -d
}

make_micro_dumps() {
  generate_micro_dump_optimization_sql "${1}"
  unpack_db_dump_to_chunks
  replace_in_file
  adapt_chunks_to_micro_dumps
}

generate_micro_dump_optimization_sql () {
  local dump_dir="${1}"
  prepend="SET GLOBAL max_connections = 200;"
  prepend="$prepend SET UNIQUE_CHECKS = 0; "
  prepend="$prepend SET AUTOCOMMIT = 0; "
  echo $prepend > $dump_dir/prepend.sql

  append="SET UNIQUE_CHECKS = 1; "
  append="$append SET AUTOCOMMIT = 1; "
  append="$append COMMIT ; "
  echo $append > $dump_dir/append.sql
}

unpack_db_dump_to_chunks() {
  if gzip -dc /root/${dump_path} | csplit -s -ftable - "/-- Table structure for table/" {*}; then
    echo 'Success split dump tables'
  else
    echo -e '\e[31mDump tables split failed\e[0m'
    exit 1
  fi
}

replace_in_file() {
  if [[ ! -z "${replace_table_prefix_from}" ]] && [[ $replace_table_prefix_from != $replace_table_prefix_to ]]; then
    sed -i "s/$replace_table_prefix_from/$replace_table_prefix_to/" $1
  fi
}

adapt_chunks_to_micro_dumps() {
  mv table00 head
  for file in `ls -1 table*`; do
    table_name=`head -n1 $file | cut -d$'\x60' -f2`
    cat head prepend.sql $file append.sql > "$table_name.sql"
    replace_in_file "$table_name.sql"
  done
  echo "Split to micro dumps successfully completed"
}

clean_up_db() {
  #rm prepend.sql append.sql head table*
  mysql -e "DROP DATABASE $db_name; CREATE DATABASE $db_name"
}

mysql_import(){
  mysql $2 < $1
}

async_restore_dump() {
  for file in *; do
    mysql_import "$file" "$db_name" &

    table_name=${file%".sql"}
    if [[ ! "$table_name" =~ $asynchronously_imported_tables_regex ]]; then
      pids+=($!)
    fi
  done

  wait "${pids[@]}"
  echo "Async dump restore successfully completed"
}

remove_dir() {
  local dump_dir="${1}"
  rm -rf $dump_dir
}

parse_options "$@"
ensure_options_are_valid
ensure_nobody_is_using_database

working_dir=$(make_dump_dir)
cd $working_dir
make_micro_dumps $working_dir
clean_up_db
mysql_import
async_restore_dump
cd
remove_dir $working_dir

echo "Some parts of the dump will be imported in background. "
